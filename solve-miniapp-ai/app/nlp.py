import torch
from transformers import AutoTokenizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from app.model_architecture import SolveMeUrgencyNet

class NLPProcessor:
    def __init__(self):
        print("Loading Custom Trained Model... üß†")
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # 1. ‡πÇ‡∏´‡∏•‡∏î Tokenizer
        try:
            self.tokenizer = AutoTokenizer.from_pretrained('./saved_tokenizer')
        except:
            # Fallback ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡πá‡∏ï
            self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

        # 2. ‡πÇ‡∏´‡∏•‡∏î Model Architecture & Weights
        self.model = SolveMeUrgencyNet()
        try:
            # ‡πÇ‡∏´‡∏•‡∏î‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏™‡∏°‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤ (Weights)
            self.model.load_state_dict(torch.load('solveme_urgency_model.pth', map_location=self.device))
            print("‚úÖ Custom Weights Loaded Successfully!")
        except FileNotFoundError:
            print("‚ö†Ô∏è Warning: Model weights not found. Using untrained model.")
        
        self.model.to(self.device)
        self.model.eval() # ‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏´‡∏°‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á (‡∏õ‡∏¥‡∏î Dropout)

    def get_embedding(self, text: str):
        """‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Matching (‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ BERT Backbone ‡πÄ‡∏î‡∏¥‡∏°)"""
        inputs = self.tokenizer(text, return_tensors="pt", padding=True, truncation=True).to(self.device)
        with torch.no_grad():
            outputs = self.model.bert(**inputs)
            # Mean Pooling
            token_embeddings = outputs.last_hidden_state
            mask = inputs['attention_mask'].unsqueeze(-1).expand(token_embeddings.size()).float()
            sum_embeddings = torch.sum(token_embeddings * mask, 1)
            sum_mask = torch.clamp(mask.sum(1), min=1e-9)
            return (sum_embeddings / sum_mask).cpu().numpy()

    def calculate_urgency(self, text: str) -> dict:
        """
        ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Custom ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πà‡∏ß‡∏ô (0-1) ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á!
        (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Anchors ‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß)
        """
        inputs = self.tokenizer(text, return_tensors="pt", padding=True, truncation=True).to(self.device)
        
        with torch.no_grad():
            # ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏•‡∏¢ (‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 0 - 1)
            score = self.model(inputs['input_ids'], inputs['attention_mask']).item()
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå
        urgency_score = round(score * 100, 2)

        # Map SLA (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
        if urgency_score >= 75:
            sla = {"tier": "P1 (Critical)", "mins": 15, "color": "#FF0000", "size": "huge"}
        elif urgency_score >= 50:
            sla = {"tier": "P2 (High)", "mins": 30, "color": "#FF8C00", "size": "large"}
        elif urgency_score >= 25:
            sla = {"tier": "P3 (Medium)", "mins": 60, "color": "#FFD700", "size": "normal"}
        else:
            sla = {"tier": "P4 (Low)", "mins": 120, "color": "#00BFFF", "size": "small"}

        return {
            "score": urgency_score,
            "sla": sla
        }

    def extract_keywords(self, text: str, top_n: int = 3):
        # (‡πÉ‡∏ä‡πâ Logic ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡πá‡πÑ‡∏î‡πâ)
        n_gram_range = (1, 1)
        try:
            count = CountVectorizer(ngram_range=n_gram_range).fit([text])
            candidates = count.get_feature_names_out()
        except ValueError:
            return []
        
        doc_emb = self.get_embedding(text)
        cand_emb = self.get_embedding(candidates) # ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ get_embedding ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö batch ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß
        
        # ... (‡∏™‡πà‡∏ß‡∏ô Keyword ‡πÉ‡∏ä‡πâ Logic ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢) ...
        return [] 

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Instance
nlp_service = NLPProcessor()